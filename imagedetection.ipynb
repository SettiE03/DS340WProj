{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn2YetG1PM3Y",
        "outputId": "d9674766-5f91-49e8-c260-32813a73d96e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path_ai = '/content/drive/MyDrive/ds340/ai_images'\n",
        "print(f\"Contents of {path_ai}:\")\n",
        "print(os.listdir(path_ai))  # This should list your AI images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8solFN_Piv6",
        "outputId": "42d9814b-4a5c-4be6-97cb-af4110c5fd35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive/MyDrive/ds340/ai_images:\n",
            "['6-234077831-733567.jpg', '6-234246248-91184.jpg', '6-234417221-62825.jpg', '6-236710992-255071.jpg', '6-237822277-478212_ai.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtMvfwuhPLWb",
        "outputId": "3599532f-4260-4a90-9f1c-e768e5e23464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed training data shape: (10, 256, 256, 1)\n",
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7833 - loss: 4.8856 - val_accuracy: 0.5000 - val_loss: 1.0093\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 688ms/step - accuracy: 0.6000 - loss: 0.8559 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.5333 - loss: 0.7029 - val_accuracy: 0.5000 - val_loss: 0.7256\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 763ms/step - accuracy: 0.4667 - loss: 0.7259 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 865ms/step - accuracy: 0.5333 - loss: 0.6882 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
            "Model saved to /content/drive/MyDrive/ds340/checkpoints/my_model.keras\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Your special processing method\n",
        "def smash_n_reconstruct(filepath):\n",
        "    # Actual logic to read and process the image\n",
        "    # Replace with your real image processing logic\n",
        "    rich_texture = np.random.rand(256, 256).astype(np.float32)  # Mock data for rich texture\n",
        "    poor_texture = np.random.rand(256, 256).astype(np.float32)  # Mock data for poor texture\n",
        "    return rich_texture, poor_texture\n",
        "\n",
        "def preprocess(filepath):\n",
        "    # Load the image using the special processing method\n",
        "    rich_texture, poor_texture = smash_n_reconstruct(filepath)\n",
        "\n",
        "    # Ensure the outputs are grayscale images of shape (256, 256, 1)\n",
        "    rich_texture = np.expand_dims(rich_texture, axis=-1)  # Shape: (256, 256, 1)\n",
        "    poor_texture = np.expand_dims(poor_texture, axis=-1)  # Shape: (256, 256, 1)\n",
        "\n",
        "    # Convert to tf.float32 for TensorFlow\n",
        "    rich_texture = tf.convert_to_tensor(rich_texture, dtype=tf.float32)\n",
        "    poor_texture = tf.convert_to_tensor(poor_texture, dtype=tf.float32)\n",
        "\n",
        "    return rich_texture, poor_texture\n",
        "\n",
        "# Load your image paths and labels\n",
        "path_ai = '/content/drive/MyDrive/ds340/ai_images'\n",
        "path_real = '/content/drive/MyDrive/ds340/real_images'\n",
        "\n",
        "# Load AI images\n",
        "ai_imgs = [os.path.join(path_ai, img) for img in os.listdir(path_ai)]\n",
        "ai_labels = [1] * len(ai_imgs)  # 1 for AI-generated images\n",
        "\n",
        "# Load real images\n",
        "real_imgs = [os.path.join(path_real, img) for img in os.listdir(path_real)]\n",
        "real_labels = [0] * len(real_imgs)  # 0 for real images\n",
        "\n",
        "# Combine image paths and labels\n",
        "X_train = ai_imgs + real_imgs\n",
        "y_train = ai_labels + real_labels\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(X_train, y_train))\n",
        "np.random.shuffle(combined)\n",
        "X_train[:], y_train[:] = zip(*combined)\n",
        "\n",
        "# Preprocess all images\n",
        "X_processed = []\n",
        "for filepath in X_train:\n",
        "    rich_texture, poor_texture = preprocess(filepath)\n",
        "    # Only appending rich textures for the training set\n",
        "    X_processed.append(rich_texture.numpy())  # Convert tensor to numpy array for the dataset\n",
        "\n",
        "# Convert to numpy array and check the shape\n",
        "X_processed = np.array(X_processed)\n",
        "\n",
        "# Check the shape of processed data\n",
        "print(f\"Processed training data shape: {X_processed.shape}\")  # Expecting (num_samples, 256, 256, 1)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(256, 256, 1)),  # Input shape for grayscale images\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_processed, y_train, epochs=5, batch_size=2, validation_split=0.2)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/ds340/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uadf0SxS_L7",
        "outputId": "1d2c19c6-0955-4c46-95a9-51904b98225f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ai_images  checkpoints\tevaluate  preprocessing  real_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from tensorflow.keras.models import load_model\n",
        "import sys\n",
        "\n",
        "# Add path to preprocessing module if it is on Google Drive\n",
        "sys.path.append('/content/drive/MyDrive/ds340/')\n",
        "\n",
        "# Now import the module\n",
        "from preprocessing.patch_generator import smash_n_reconstruct  # Using your existing texture analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def prepare_background_data(num_samples=10):\n",
        "    \"\"\"\n",
        "    Prepare background data for SHAP analysis using both AI and real images.\n",
        "    \"\"\"\n",
        "    background_data = []\n",
        "\n",
        "    # Add paths to some representative background images\n",
        "    background_paths = [\n",
        "        '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg',\n",
        "        # ... add more paths here\n",
        "    ]\n",
        "\n",
        "    for path in background_paths[:num_samples]:\n",
        "        rich_texture, _ = smash_n_reconstruct(path, coloured=False)\n",
        "        rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "        if rich_texture.shape != (256, 256, 1):\n",
        "            rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "        background_data.append(rich_texture)\n",
        "\n",
        "    return np.stack(background_data)\n",
        "\n",
        "def preprocess_single_image(image_path):\n",
        "    \"\"\"Preprocess a single image for prediction and SHAP analysis.\"\"\"\n",
        "    rich_texture, _ = smash_n_reconstruct(image_path, coloured=False)\n",
        "    rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "    if rich_texture.shape != (256, 256, 1):\n",
        "        rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "\n",
        "    return np.expand_dims(rich_texture, axis=0)  # Add batch dimension\n",
        "\n",
        "def explain_prediction(model_path, image_path, num_background_samples=10):\n",
        "    \"\"\"Generate and visualize SHAP explanations for a single image prediction.\"\"\"\n",
        "    model = load_model(model_path)\n",
        "    test_image = preprocess_single_image(image_path)\n",
        "    print(f\"Test image shape: {test_image.shape}\")\n",
        "\n",
        "    background_data = prepare_background_data(num_background_samples)\n",
        "    print(f\"Background data shape: {background_data.shape}\")\n",
        "\n",
        "    explainer = shap.DeepExplainer(model, background_data)\n",
        "    shap_values = explainer.shap_values(test_image)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[0]\n",
        "\n",
        "    abs_shap_values = np.abs(shap_values)\n",
        "    max_value = np.percentile(abs_shap_values, 99)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.title('SHAP Values')\n",
        "    plt.imshow(shap_values[0, :, :, 0], cmap='RdBu', vmin=-max_value, vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.title('Absolute SHAP Values')\n",
        "    plt.imshow(abs_shap_values[0, :, :, 0], cmap='hot', vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/shap_explanation_3.png')\n",
        "    plt.close()\n",
        "\n",
        "    prediction = model.predict(test_image)[0][0]\n",
        "    return shap_values, prediction\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set paths to Google Drive locations\n",
        "    MODEL_PATH = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "    TEST_IMAGE_PATH = '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg'\n",
        "\n",
        "    shap_values, prediction = explain_prediction(\n",
        "        model_path=MODEL_PATH,\n",
        "        image_path=TEST_IMAGE_PATH,\n",
        "        num_background_samples=10\n",
        "    )\n",
        "\n",
        "    print(f\"Prediction: {prediction:.3f}\")\n",
        "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "    print(\"Explanation has been saved as 'shap_explanation_3.png'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2VxLkW-Q3e2",
        "outputId": "f994ec8e-ad22-416f-ddd9-9349ea62c4e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Test image shape: (1, 256, 256, 1)\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Background data shape: (1, 256, 256, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "Prediction: 0.500\n",
            "SHAP values shape: (1, 256, 256, 1, 1)\n",
            "Explanation has been saved as 'shap_explanation_3.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from tensorflow.keras.models import load_model\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Add path to preprocessing module if it is on Google Drive\n",
        "sys.path.append('/content/drive/MyDrive/ds340/')\n",
        "from preprocessing.patch_generator import smash_n_reconstruct  # Using your existing texture analysis\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def prepare_background_data(num_samples=10):\n",
        "    \"\"\"\n",
        "    Prepare background data for SHAP analysis using both AI and real images.\n",
        "    \"\"\"\n",
        "    background_data = []\n",
        "\n",
        "    background_paths = [\n",
        "        '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg',\n",
        "        # Add more paths if needed\n",
        "    ]\n",
        "\n",
        "    for path in background_paths[:num_samples]:\n",
        "        rich_texture, _ = smash_n_reconstruct(path, coloured=False)\n",
        "        rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "        if rich_texture.shape != (256, 256, 1):\n",
        "            rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "        background_data.append(rich_texture)\n",
        "\n",
        "    return np.stack(background_data)\n",
        "\n",
        "def preprocess_single_image(image_path):\n",
        "    \"\"\"Preprocess a single image for prediction and SHAP analysis.\"\"\"\n",
        "    rich_texture, _ = smash_n_reconstruct(image_path, coloured=False)\n",
        "    rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "    if rich_texture.shape != (256, 256, 1):\n",
        "        rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "\n",
        "    return np.expand_dims(rich_texture, axis=0)  # Add batch dimension\n",
        "\n",
        "def overlay_shap_on_image(image, shap_values, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Overlay SHAP values on the original image.\n",
        "    \"\"\"\n",
        "    overlay = np.squeeze(shap_values)  # Remove unnecessary dimensions\n",
        "    normalized_overlay = (overlay - overlay.min()) / (overlay.max() - overlay.min())  # Normalize to [0,1]\n",
        "\n",
        "    reconstructed_image = np.squeeze(image)  # Convert to 2D if necessary\n",
        "    plt.imshow(reconstructed_image, cmap='gray', alpha=1)  # Base image in grayscale\n",
        "    plt.imshow(normalized_overlay, cmap='RdBu', alpha=alpha, vmin=0, vmax=1)  # SHAP overlay\n",
        "    plt.axis('off')\n",
        "    plt.title('Reconstructed Image with SHAP Overlay')\n",
        "\n",
        "def explain_with_shapv2(model_path, image_path, num_background_samples=10):\n",
        "    \"\"\"Generate and visualize SHAP explanations, including a reconstructed image with SHAP values.\"\"\"\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Preprocess the input image\n",
        "    test_image = preprocess_single_image(image_path)\n",
        "    print(f\"Test image shape: {test_image.shape}\")\n",
        "\n",
        "    # Prepare background data\n",
        "    background_data = prepare_background_data(num_background_samples)\n",
        "    print(f\"Background data shape: {background_data.shape}\")\n",
        "\n",
        "    # Create SHAP explainer and compute SHAP values\n",
        "    explainer = shap.DeepExplainer(model, background_data)\n",
        "    shap_values = explainer.shap_values(test_image)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[0]\n",
        "\n",
        "    abs_shap_values = np.abs(shap_values)\n",
        "    max_value = np.percentile(abs_shap_values, 99)\n",
        "\n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # SHAP Values\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.title('SHAP Values')\n",
        "    plt.imshow(shap_values[0, :, :, 0], cmap='RdBu', vmin=-max_value, vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Absolute SHAP Values\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.title('Absolute SHAP Values')\n",
        "    plt.imshow(abs_shap_values[0, :, :, 0], cmap='hot', vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed Image with SHAP Overlay\n",
        "    plt.subplot(2, 2, 4)\n",
        "    overlay_shap_on_image(test_image[0], shap_values[0])\n",
        "\n",
        "    # Save the visualizations\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/shap_explanation_v2.png')\n",
        "    plt.close()\n",
        "    print(\"Explanation with overlay saved as 'shap_explanation_v2.png'.\")\n",
        "\n",
        "    # Make a prediction and return SHAP values and prediction\n",
        "    prediction = model.predict(test_image)[0][0]\n",
        "    return shap_values, prediction\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set paths to Google Drive locations\n",
        "    MODEL_PATH = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "    TEST_IMAGE_PATH = '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg'\n",
        "\n",
        "    # Generate explanations and display the prediction\n",
        "    shap_values, prediction = explain_with_shapv2(\n",
        "        model_path=MODEL_PATH,\n",
        "        image_path=TEST_IMAGE_PATH,\n",
        "        num_background_samples=10\n",
        "    )\n",
        "\n",
        "    print(f\"Prediction: {prediction:.3f}\")\n",
        "    print(f\"SHAP values shape: {shap_values.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rsWIu6jUWo-",
        "outputId": "3570ca3f-73e7-477d-fe5f-322af332d487"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Test image shape: (1, 256, 256, 1)\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Background data shape: (1, 256, 256, 1)\n",
            "Explanation with overlay saved as 'shap_explanation_v2.png'.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Prediction: 0.500\n",
            "SHAP values shape: (1, 256, 256, 1, 1)\n"
          ]
        }
      ]
    }
  ]
}