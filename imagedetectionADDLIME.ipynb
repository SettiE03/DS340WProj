{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fc680f5d0eb407792d78c3c0481e8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a84283f9b9d407a9932c25f809a6a3a",
              "IPY_MODEL_70841877efbd4ab68982f7fe765b4586",
              "IPY_MODEL_6699190f0edb4de99a211e49e99f7f5e"
            ],
            "layout": "IPY_MODEL_5067e52364314f299784b96e6c334583"
          }
        },
        "1a84283f9b9d407a9932c25f809a6a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02f5cc6b27446b3984c6aa394f48543",
            "placeholder": "​",
            "style": "IPY_MODEL_24415afa781a47aa99cc0d68f9b9d5c7",
            "value": "100%"
          }
        },
        "70841877efbd4ab68982f7fe765b4586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_718b04c7448b4edc8d3f18b223d1357b",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_618eb421aa7c4893b6d241a402deb0c6",
            "value": 1000
          }
        },
        "6699190f0edb4de99a211e49e99f7f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c39821909f941d583564abac3345012",
            "placeholder": "​",
            "style": "IPY_MODEL_6c664eb1c08441aca39755fdc807310a",
            "value": " 1000/1000 [01:01&lt;00:00, 15.66it/s]"
          }
        },
        "5067e52364314f299784b96e6c334583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02f5cc6b27446b3984c6aa394f48543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24415afa781a47aa99cc0d68f9b9d5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "718b04c7448b4edc8d3f18b223d1357b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618eb421aa7c4893b6d241a402deb0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c39821909f941d583564abac3345012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c664eb1c08441aca39755fdc807310a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn2YetG1PM3Y",
        "outputId": "80b86e12-8dfc-46ab-c584-bd0225d65e6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path_ai = '/content/drive/MyDrive/ds340/ai_images'\n",
        "print(f\"Contents of {path_ai}:\")\n",
        "print(os.listdir(path_ai))  # This should list your AI images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8solFN_Piv6",
        "outputId": "13c4d6fd-c5fb-46e4-a7ad-e31dfccd6e98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive/MyDrive/ds340/ai_images:\n",
            "['6-234077831-733567.jpg', '6-234246248-91184.jpg', '6-234417221-62825.jpg', '6-236710992-255071.jpg', '6-237822277-478212_ai.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtMvfwuhPLWb",
        "outputId": "30e53839-9e07-4dc5-c498-a16325dc10fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed training data shape: (10, 256, 256, 1)\n",
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 826ms/step - accuracy: 0.6000 - loss: 7.1847 - val_accuracy: 0.5000 - val_loss: 0.7564\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 922ms/step - accuracy: 0.2167 - loss: 0.9091 - val_accuracy: 0.5000 - val_loss: 0.6961\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693ms/step - accuracy: 0.6500 - loss: 0.8058 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 679ms/step - accuracy: 0.6500 - loss: 0.6728 - val_accuracy: 0.5000 - val_loss: 0.6966\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.7333 - loss: 0.6904 - val_accuracy: 0.5000 - val_loss: 0.7029\n",
            "Model saved to /content/drive/MyDrive/ds340/checkpoints/my_model.keras\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Your special processing method\n",
        "def smash_n_reconstruct(filepath):\n",
        "    # Actual logic to read and process the image\n",
        "    # Replace with your real image processing logic\n",
        "    rich_texture = np.random.rand(256, 256).astype(np.float32)  # Mock data for rich texture\n",
        "    poor_texture = np.random.rand(256, 256).astype(np.float32)  # Mock data for poor texture\n",
        "    return rich_texture, poor_texture\n",
        "\n",
        "def preprocess(filepath):\n",
        "    # Load the image using the special processing method\n",
        "    rich_texture, poor_texture = smash_n_reconstruct(filepath)\n",
        "\n",
        "    # Ensure the outputs are grayscale images of shape (256, 256, 1)\n",
        "    rich_texture = np.expand_dims(rich_texture, axis=-1)  # Shape: (256, 256, 1)\n",
        "    poor_texture = np.expand_dims(poor_texture, axis=-1)  # Shape: (256, 256, 1)\n",
        "\n",
        "    # Convert to tf.float32 for TensorFlow\n",
        "    rich_texture = tf.convert_to_tensor(rich_texture, dtype=tf.float32)\n",
        "    poor_texture = tf.convert_to_tensor(poor_texture, dtype=tf.float32)\n",
        "\n",
        "    return rich_texture, poor_texture\n",
        "\n",
        "# Load your image paths and labels\n",
        "path_ai = '/content/drive/MyDrive/ds340/ai_images'\n",
        "path_real = '/content/drive/MyDrive/ds340/real_images'\n",
        "\n",
        "# Load AI images\n",
        "ai_imgs = [os.path.join(path_ai, img) for img in os.listdir(path_ai)]\n",
        "ai_labels = [1] * len(ai_imgs)  # 1 for AI-generated images\n",
        "\n",
        "# Load real images\n",
        "real_imgs = [os.path.join(path_real, img) for img in os.listdir(path_real)]\n",
        "real_labels = [0] * len(real_imgs)  # 0 for real images\n",
        "\n",
        "# Combine image paths and labels\n",
        "X_train = ai_imgs + real_imgs\n",
        "y_train = ai_labels + real_labels\n",
        "\n",
        "# Shuffle the dataset\n",
        "combined = list(zip(X_train, y_train))\n",
        "np.random.shuffle(combined)\n",
        "X_train[:], y_train[:] = zip(*combined)\n",
        "\n",
        "# Preprocess all images\n",
        "X_processed = []\n",
        "for filepath in X_train:\n",
        "    rich_texture, poor_texture = preprocess(filepath)\n",
        "    # Only appending rich textures for the training set\n",
        "    X_processed.append(rich_texture.numpy())  # Convert tensor to numpy array for the dataset\n",
        "\n",
        "# Convert to numpy array and check the shape\n",
        "X_processed = np.array(X_processed)\n",
        "\n",
        "# Check the shape of processed data\n",
        "print(f\"Processed training data shape: {X_processed.shape}\")  # Expecting (num_samples, 256, 256, 1)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(256, 256, 1)),  # Input shape for grayscale images\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_processed, y_train, epochs=5, batch_size=2, validation_split=0.2)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "\n",
        "# Create the directory in Google Drive if it doesn't exist\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/ds340/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uadf0SxS_L7",
        "outputId": "64794d89-96be-413f-a9c1-927f289dc8c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ai_images  checkpoints\tevaluate  preprocessing  real_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from tensorflow.keras.models import load_model\n",
        "import sys\n",
        "\n",
        "# Add path to preprocessing module if it is on Google Drive\n",
        "sys.path.append('/content/drive/MyDrive/ds340/')\n",
        "\n",
        "# Now import the module\n",
        "from preprocessing.patch_generator import smash_n_reconstruct  # Using your existing texture analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def prepare_background_data(num_samples=10):\n",
        "    \"\"\"\n",
        "    Prepare background data for SHAP analysis using both AI and real images.\n",
        "    \"\"\"\n",
        "    background_data = []\n",
        "\n",
        "    # Add paths to some representative background images\n",
        "    background_paths = [\n",
        "        '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg',\n",
        "        # ... add more paths here\n",
        "    ]\n",
        "\n",
        "    for path in background_paths[:num_samples]:\n",
        "        rich_texture, _ = smash_n_reconstruct(path, coloured=False)\n",
        "        rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "        if rich_texture.shape != (256, 256, 1):\n",
        "            rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "        background_data.append(rich_texture)\n",
        "\n",
        "    return np.stack(background_data)\n",
        "\n",
        "def preprocess_single_image(image_path):\n",
        "    \"\"\"Preprocess a single image for prediction and SHAP analysis.\"\"\"\n",
        "    rich_texture, _ = smash_n_reconstruct(image_path, coloured=False)\n",
        "    rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "    if rich_texture.shape != (256, 256, 1):\n",
        "        rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "\n",
        "    return np.expand_dims(rich_texture, axis=0)  # Add batch dimension\n",
        "\n",
        "def explain_prediction(model_path, image_path, num_background_samples=10):\n",
        "    \"\"\"Generate and visualize SHAP explanations for a single image prediction.\"\"\"\n",
        "    model = load_model(model_path)\n",
        "    test_image = preprocess_single_image(image_path)\n",
        "    print(f\"Test image shape: {test_image.shape}\")\n",
        "\n",
        "    background_data = prepare_background_data(num_background_samples)\n",
        "    print(f\"Background data shape: {background_data.shape}\")\n",
        "\n",
        "    explainer = shap.DeepExplainer(model, background_data)\n",
        "    shap_values = explainer.shap_values(test_image)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[0]\n",
        "\n",
        "    abs_shap_values = np.abs(shap_values)\n",
        "    max_value = np.percentile(abs_shap_values, 99)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.title('SHAP Values')\n",
        "    plt.imshow(shap_values[0, :, :, 0], cmap='RdBu', vmin=-max_value, vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.title('Absolute SHAP Values')\n",
        "    plt.imshow(abs_shap_values[0, :, :, 0], cmap='hot', vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/shap_explanation_3.png')\n",
        "    plt.close()\n",
        "\n",
        "    prediction = model.predict(test_image)[0][0]\n",
        "    return shap_values, prediction\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set paths to Google Drive locations\n",
        "    MODEL_PATH = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "    TEST_IMAGE_PATH = '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg'\n",
        "\n",
        "    shap_values, prediction = explain_prediction(\n",
        "        model_path=MODEL_PATH,\n",
        "        image_path=TEST_IMAGE_PATH,\n",
        "        num_background_samples=10\n",
        "    )\n",
        "\n",
        "    print(f\"Prediction: {prediction:.3f}\")\n",
        "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "    print(\"Explanation has been saved as 'shap_explanation_3.png'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2VxLkW-Q3e2",
        "outputId": "5cb1d062-ce95-4e8e-fa29-8f4122401e9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Test image shape: (1, 256, 256, 1)\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Background data shape: (1, 256, 256, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "Prediction: 0.497\n",
            "SHAP values shape: (1, 256, 256, 1, 1)\n",
            "Explanation has been saved as 'shap_explanation_3.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from tensorflow.keras.models import load_model\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Add path to preprocessing module if it is on Google Drive\n",
        "sys.path.append('/content/drive/MyDrive/ds340/')\n",
        "from preprocessing.patch_generator import smash_n_reconstruct  # Using your existing texture analysis\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def prepare_background_data(num_samples=10):\n",
        "    \"\"\"\n",
        "    Prepare background data for SHAP analysis using both AI and real images.\n",
        "    \"\"\"\n",
        "    background_data = []\n",
        "\n",
        "    background_paths = [\n",
        "        '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg',\n",
        "        # Add more paths if needed\n",
        "    ]\n",
        "\n",
        "    for path in background_paths[:num_samples]:\n",
        "        rich_texture, _ = smash_n_reconstruct(path, coloured=False)\n",
        "        rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "        if rich_texture.shape != (256, 256, 1):\n",
        "            rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "        background_data.append(rich_texture)\n",
        "\n",
        "    return np.stack(background_data)\n",
        "\n",
        "def preprocess_single_image(image_path):\n",
        "    \"\"\"Preprocess a single image for prediction and SHAP analysis.\"\"\"\n",
        "    rich_texture, _ = smash_n_reconstruct(image_path, coloured=False)\n",
        "    rich_texture = rich_texture.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "    if rich_texture.shape != (256, 256, 1):\n",
        "        rich_texture = np.reshape(rich_texture, (256, 256, 1))\n",
        "\n",
        "    return np.expand_dims(rich_texture, axis=0)  # Add batch dimension\n",
        "\n",
        "def overlay_shap_on_image(image, shap_values, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Overlay SHAP values on the original image.\n",
        "    \"\"\"\n",
        "    overlay = np.squeeze(shap_values)  # Remove unnecessary dimensions\n",
        "    normalized_overlay = (overlay - overlay.min()) / (overlay.max() - overlay.min())  # Normalize to [0,1]\n",
        "\n",
        "    reconstructed_image = np.squeeze(image)  # Convert to 2D if necessary\n",
        "    plt.imshow(reconstructed_image, cmap='gray', alpha=1)  # Base image in grayscale\n",
        "    plt.imshow(normalized_overlay, cmap='RdBu', alpha=alpha, vmin=0, vmax=1)  # SHAP overlay\n",
        "    plt.axis('off')\n",
        "    plt.title('Reconstructed Image with SHAP Overlay')\n",
        "\n",
        "def explain_with_shapv2(model_path, image_path, num_background_samples=10):\n",
        "    \"\"\"Generate and visualize SHAP explanations, including a reconstructed image with SHAP values.\"\"\"\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Preprocess the input image\n",
        "    test_image = preprocess_single_image(image_path)\n",
        "    print(f\"Test image shape: {test_image.shape}\")\n",
        "\n",
        "    # Prepare background data\n",
        "    background_data = prepare_background_data(num_background_samples)\n",
        "    print(f\"Background data shape: {background_data.shape}\")\n",
        "\n",
        "    # Create SHAP explainer and compute SHAP values\n",
        "    explainer = shap.DeepExplainer(model, background_data)\n",
        "    shap_values = explainer.shap_values(test_image)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[0]\n",
        "\n",
        "    abs_shap_values = np.abs(shap_values)\n",
        "    max_value = np.percentile(abs_shap_values, 99)\n",
        "\n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(test_image[0, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # SHAP Values\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.title('SHAP Values')\n",
        "    plt.imshow(shap_values[0, :, :, 0], cmap='RdBu', vmin=-max_value, vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Absolute SHAP Values\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.title('Absolute SHAP Values')\n",
        "    plt.imshow(abs_shap_values[0, :, :, 0], cmap='hot', vmax=max_value)\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed Image with SHAP Overlay\n",
        "    plt.subplot(2, 2, 4)\n",
        "    overlay_shap_on_image(test_image[0], shap_values[0])\n",
        "\n",
        "    # Save the visualizations\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/shap_explanation_v2.png')\n",
        "    plt.close()\n",
        "    print(\"Explanation with overlay saved as 'shap_explanation_v2.png'.\")\n",
        "\n",
        "    # Make a prediction and return SHAP values and prediction\n",
        "    prediction = model.predict(test_image)[0][0]\n",
        "    return shap_values, prediction\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set paths to Google Drive locations\n",
        "    MODEL_PATH = '/content/drive/MyDrive/ds340/checkpoints/my_model.keras'\n",
        "    TEST_IMAGE_PATH = '/content/drive/MyDrive/ds340/evaluate/7-103192408-508471_ai_2.jpg'\n",
        "\n",
        "    # Generate explanations and display the prediction\n",
        "    shap_values, prediction = explain_with_shapv2(\n",
        "        model_path=MODEL_PATH,\n",
        "        image_path=TEST_IMAGE_PATH,\n",
        "        num_background_samples=10\n",
        "    )\n",
        "\n",
        "    print(f\"Prediction: {prediction:.3f}\")\n",
        "    print(f\"SHAP values shape: {shap_values.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rsWIu6jUWo-",
        "outputId": "57ee4961-470a-4aa8-f0af-dc7371c19175"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Test image shape: (1, 256, 256, 1)\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n",
            "Background data shape: (1, 256, 256, 1)\n",
            "Explanation with overlay saved as 'shap_explanation_v2.png'.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Prediction: 0.497\n",
            "SHAP values shape: (1, 256, 256, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding LIME for image model interpretability\n",
        "\n",
        "# Install LIME if not already installed\n",
        "!pip install lime\n",
        "\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize the LimeImageExplainer\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Example: Choose a sample image to explain\n",
        "sample_index = 0  # Change to the index of the image you want to explain\n",
        "image_path = X_train[sample_index]\n",
        "\n",
        "# Preprocess the image for the model (adapt this to your preprocessing steps)\n",
        "rich_texture, _ = preprocess(image_path)  # Replace this with your real preprocessing function\n",
        "\n",
        "# Ensure the input image has the correct shape\n",
        "image_to_explain = rich_texture.numpy()  # Convert to numpy\n",
        "if image_to_explain.shape[-1] == 1:  # If grayscale, expand to 3 channels for LIME\n",
        "    image_to_explain = np.repeat(image_to_explain, 3, axis=-1)\n",
        "\n",
        "# Define a wrapper function for the model prediction\n",
        "def model_predict_wrapper(images):\n",
        "    # Convert RGB images back to grayscale and add batch and channel dimensions\n",
        "    images_gray = np.mean(images, axis=-1, keepdims=True)  # Convert RGB to grayscale\n",
        "    return model.predict(images_gray)\n",
        "\n",
        "# Get explanation for the image\n",
        "explanation = explainer.explain_instance(\n",
        "    image=image_to_explain.squeeze(),  # Input image\n",
        "    classifier_fn=model_predict_wrapper,  # Wrapped predict function\n",
        "    top_labels=2,\n",
        "    hide_color=0,\n",
        "    num_samples=1000  # Number of perturbations\n",
        ")\n",
        "\n",
        "# Dynamically select the label to visualize\n",
        "label_to_visualize = explanation.top_labels[0]  # Select the top predicted label\n",
        "\n",
        "# Visualize the explanation\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    label=label_to_visualize,  # Dynamically select the label\n",
        "    positive_only=True,\n",
        "    num_features=10,\n",
        "    hide_rest=False\n",
        ")\n",
        "\n",
        "# Display the image with explanations\n",
        "plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
        "plt.title(f\"LIME Explanation for Label {label_to_visualize}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9fc680f5d0eb407792d78c3c0481e8cb",
            "1a84283f9b9d407a9932c25f809a6a3a",
            "70841877efbd4ab68982f7fe765b4586",
            "6699190f0edb4de99a211e49e99f7f5e",
            "5067e52364314f299784b96e6c334583",
            "c02f5cc6b27446b3984c6aa394f48543",
            "24415afa781a47aa99cc0d68f9b9d5c7",
            "718b04c7448b4edc8d3f18b223d1357b",
            "618eb421aa7c4893b6d241a402deb0c6",
            "2c39821909f941d583564abac3345012",
            "6c664eb1c08441aca39755fdc807310a"
          ]
        },
        "id": "p0ii4CH0R-7E",
        "outputId": "2446e8fd-3da4-4e67-a176-56716a4017a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Generated 64 grayscale patches and 64 color patches.\n",
            "Rich Texture Shape: (256, 256, 1), Poor Texture Shape: (256, 256, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fc680f5d0eb407792d78c3c0481e8cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}